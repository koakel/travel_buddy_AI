import pandas as pd
import numpy as np
import os
import re
import pickle
import json
from typing import Dict, List, Any, Optional, Tuple, Union
from sentence_transformers import SentenceTransformer
import faiss
import datetime


class DataRetrievalModule:
    """æ•°æ®æ£€ç´¢æ¨¡å—ï¼šå¤„ç†æ™¯ç‚¹å’Œå•†å®¶ä¿¡æ¯æ£€ç´¢"""

    def __init__(self, data_dir: str = "data", model_name: str = "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"):
        """
        åˆå§‹åŒ–æ•°æ®æ£€ç´¢æ¨¡å—

        Args:
            data_dir: æ•°æ®æ–‡ä»¶å­˜æ”¾ç›®å½•
            model_name: ä½¿ç”¨çš„å‘é‡æ¨¡å‹åç§°
            use_local_model: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        """
        self.data_dir = data_dir
        self.spots_df = None  # æ™¯ç‚¹æ•°æ®
        self.merchants_df = None  # å•†å®¶æ•°æ®
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
            print(f"å·²åˆ›å»ºæ•°æ®ç›®å½•: {data_dir}")

        # åŠ è½½æ•°æ®
        self._load_data()

        # FAISSå‘é‡ç´¢å¼•
        self.spots_index = None
        self.merchants_index = None
        self.embedding_dim = 384  # é»˜è®¤åµŒå…¥ç»´åº¦ï¼Œå°†åœ¨ç”ŸæˆåµŒå…¥æ—¶æ›´æ–°

        # åˆå§‹åŒ–å‘é‡æ¨¡å‹
        try:
            # æ£€æŸ¥å½“å‰ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨modelæ–‡ä»¶å¤¹
            local_model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "model")
            if os.path.exists(local_model_path):
                print(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {local_model_path}")
                self.model = SentenceTransformer(local_model_path)
            else:
                print(f"æœ¬åœ°æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {local_model_path}ï¼Œå°†ä»äº’è”ç½‘ä¸‹è½½æ¨¡å‹")
                self.model = SentenceTransformer(model_name)
                # ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰
                os.makedirs(local_model_path, exist_ok=True)
                self.model.save(local_model_path)
                print(f"å·²å°†æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°: {local_model_path}")
                
            self.spots_embeddings = None
            self.merchants_embeddings = None
            self._generate_embeddings()
        except Exception as e:
            print(f"å‘é‡æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None

    def _load_data(self):
        """åŠ è½½æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒExcelå’ŒCSVæ ¼å¼ï¼‰"""
        # å°è¯•åŠ è½½Excelæ–‡ä»¶
        spots_xlsx_path = os.path.join(self.data_dir, "å¤§ç†æ™¯ç‚¹æ•´ç†.xlsx")
        merchants_csv_path = os.path.join(self.data_dir, "æ„å‘åˆä½œå•†å®¶.csv")

        # åˆå§‹åŒ–DataFrame
        self.spots_df = pd.DataFrame()
        self.merchants_df = pd.DataFrame()

        # å¤„ç†æ™¯ç‚¹æ•°æ®
        if os.path.exists(spots_xlsx_path):
            try:
                self.spots_df = pd.read_excel(spots_xlsx_path)
                print(f"æˆåŠŸåŠ è½½{len(self.spots_df)}ä¸ªæ™¯ç‚¹æ•°æ® (Excelæ ¼å¼)")
            except Exception as e:
                print(f"Excelæ™¯ç‚¹æ•°æ®åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½æ™¯ç‚¹æ•°æ®æ–‡ä»¶")

        # å¤„ç†å•†å®¶æ•°æ®
        if os.path.exists(merchants_csv_path):
            try:
                self.merchants_df = pd.read_csv(merchants_csv_path, encoding='utf-8')
                print(f"æˆåŠŸåŠ è½½{len(self.merchants_df)}ä¸ªå•†å®¶æ•°æ® (CSVæ ¼å¼, ç¼–ç : utf-8)")
            except Exception as e:
                print(f"å•†å®¶æ•°æ®åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½å•†å®¶æ•°æ®æ–‡ä»¶")

        # å¦‚æœä¸¤ä¸ªæ•°æ®æ–‡ä»¶éƒ½ä¸å­˜åœ¨æˆ–æ— æ³•åŠ è½½ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®
        if self.spots_df.empty and self.merchants_df.empty:
            print("æ— æ³•åŠ è½½ä»»ä½•æ•°æ®")

    def _generate_embeddings(self):
        """ä¸ºæ™¯ç‚¹å’Œå•†å®¶æ•°æ®ç”Ÿæˆå‘é‡åµŒå…¥å¹¶åˆ›å»ºFAISSç´¢å¼•"""
        if self.model is None:
            return

        # ä¸ºæ™¯ç‚¹ç”Ÿæˆå‘é‡
        if not self.spots_df.empty:
            # å°†æ™¯ç‚¹åç§°å’Œç®€ä»‹æ‹¼æ¥ä½œä¸ºç‰¹å¾æ–‡æœ¬
            spot_texts = []
            for _, row in self.spots_df.iterrows():
                text = f"{row['æ™¯ç‚¹åç§°']} {row['ç®€ä»‹']} {row['ç‰¹è‰²çœ‹ç‚¹']}"
                spot_texts.append(text)

            # ç”Ÿæˆå‘é‡
            self.spots_embeddings = self.model.encode(spot_texts)
            
            # ç¡®ä¿å‘é‡æ˜¯float32ç±»å‹å¹¶è¿›è¡ŒL2å½’ä¸€åŒ–
            self.spots_embeddings = self.spots_embeddings.astype(np.float32)
            faiss.normalize_L2(self.spots_embeddings)  # å½’ä¸€åŒ–å‘é‡
            
            print(f"å·²ç”Ÿæˆ{len(spot_texts)}ä¸ªæ™¯ç‚¹å‘é‡")
            
            # æ›´æ–°åµŒå…¥ç»´åº¦
            self.embedding_dim = self.spots_embeddings.shape[1]
            
            # åˆ›å»ºFAISSç´¢å¼• - ä½¿ç”¨IndexFlatIPè¿›è¡Œå†…ç§¯ç›¸ä¼¼åº¦ï¼ˆç±»ä¼¼äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
            self.spots_index = self._create_faiss_index(self.spots_embeddings)
            print(f"å·²åˆ›å»ºæ™¯ç‚¹FAISSç´¢å¼•")

        # ä¸ºå•†å®¶ç”Ÿæˆå‘é‡
        if not self.merchants_df.empty:
            # å°†å•†å®¶åç§°å’Œä½ç½®æ‹¼æ¥ä½œä¸ºç‰¹å¾æ–‡æœ¬
            merchant_texts = []
            for _, row in self.merchants_df.iterrows():
                text = f"{row['å•†å®¶']} {row['ä½ç½®']} {row['æˆ¿é—´å‹å·']}"
                merchant_texts.append(text)

            # ç”Ÿæˆå‘é‡
            self.merchants_embeddings = self.model.encode(merchant_texts)
            
            # ç¡®ä¿å‘é‡æ˜¯float32ç±»å‹å¹¶è¿›è¡ŒL2å½’ä¸€åŒ–
            self.merchants_embeddings = self.merchants_embeddings.astype(np.float32)
            faiss.normalize_L2(self.merchants_embeddings)  # å½’ä¸€åŒ–å‘é‡
            
            print(f"å·²ç”Ÿæˆ{len(merchant_texts)}ä¸ªå•†å®¶å‘é‡")
            
            # æ›´æ–°åµŒå…¥ç»´åº¦
            self.embedding_dim = self.merchants_embeddings.shape[1]
            
            # åˆ›å»ºFAISSç´¢å¼•
            self.merchants_index = self._create_faiss_index(self.merchants_embeddings)
            print(f"å·²åˆ›å»ºå•†å®¶FAISSç´¢å¼•")
            
        # å°è¯•ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶
        self._save_indexes()

    def _create_faiss_index(self, embeddings: np.ndarray) -> faiss.Index:
        """
        åˆ›å»ºFAISSç´¢å¼•
        
        Args:
            embeddings: åµŒå…¥å‘é‡æ•°ç»„
            
        Returns:
            FAISSç´¢å¼•å¯¹è±¡
        """
        # è·å–ç»´åº¦
        dim = embeddings.shape[1]
        
        # åˆ›å»ºç´¢å¼• - ä½¿ç”¨IndexFlatIPé€‚åˆå°æ•°æ®é›†ï¼Œå¯¹äºå¤§æ•°æ®é›†å¯ä»¥ä½¿ç”¨é‡åŒ–å™¨
        index = faiss.IndexFlatIP(dim)  # å†…ç§¯ç›¸ä¼¼åº¦ï¼Œé€‚ç”¨äºL2å½’ä¸€åŒ–çš„å‘é‡
        
        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        index.add(embeddings)
        
        return index
    
    def _save_indexes(self):
        """ä¿å­˜FAISSç´¢å¼•åˆ°æ–‡ä»¶"""
        try:
            os.makedirs(os.path.join(self.data_dir, 'indexes'), exist_ok=True)
            
            # ä¿å­˜åµŒå…¥å’Œç´¢å¼•æ•°æ®
            if self.spots_embeddings is not None and self.spots_index is not None:
                faiss.write_index(self.spots_index, os.path.join(self.data_dir, 'indexes', 'spots_index.faiss'))
                with open(os.path.join(self.data_dir, 'indexes', 'spots_embeddings.pkl'), 'wb') as f:
                    pickle.dump(self.spots_embeddings, f)
                
            if self.merchants_embeddings is not None and self.merchants_index is not None:
                faiss.write_index(self.merchants_index, os.path.join(self.data_dir, 'indexes', 'merchants_index.faiss'))
                with open(os.path.join(self.data_dir, 'indexes', 'merchants_embeddings.pkl'), 'wb') as f:
                    pickle.dump(self.merchants_embeddings, f)
                    
            print("å·²ä¿å­˜FAISSç´¢å¼•åˆ°æ–‡ä»¶")
            
        except Exception as e:
            print(f"ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    def _load_indexes(self):
        """ä»æ–‡ä»¶åŠ è½½FAISSç´¢å¼•"""
        try:
            # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶
            spots_index_path = os.path.join(self.data_dir, 'indexes', 'spots_index.faiss')
            merchants_index_path = os.path.join(self.data_dir, 'indexes', 'merchants_index.faiss')
            
            # åŠ è½½æ™¯ç‚¹ç´¢å¼•
            if os.path.exists(spots_index_path):
                self.spots_index = faiss.read_index(spots_index_path)
                embeddings_path = os.path.join(self.data_dir, 'indexes', 'spots_embeddings.pkl')
                if os.path.exists(embeddings_path):
                    with open(embeddings_path, 'rb') as f:
                        self.spots_embeddings = pickle.load(f)
                print("å·²åŠ è½½æ™¯ç‚¹FAISSç´¢å¼•")
                
            # åŠ è½½å•†å®¶ç´¢å¼•
            if os.path.exists(merchants_index_path):
                self.merchants_index = faiss.read_index(merchants_index_path)
                embeddings_path = os.path.join(self.data_dir, 'indexes', 'merchants_embeddings.pkl')
                if os.path.exists(embeddings_path):
                    with open(embeddings_path, 'rb') as f:
                        self.merchants_embeddings = pickle.load(f)
                print("å·²åŠ è½½å•†å®¶FAISSç´¢å¼•")
                
            return True
            
        except Exception as e:
            print(f"åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
            return False

    def keyword_search(self, query: str, search_type: str = "all", limit: int = 3) -> Dict[str, List[Dict]]:
        """
        åŸºäºå…³é”®è¯çš„æœç´¢

        Args:
            query: æœç´¢å…³é”®è¯
            search_type: æœç´¢ç±»å‹('spots', 'merchants', 'all')
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        results = {"spots": [], "merchants": []}

        # è§„èŒƒåŒ–æŸ¥è¯¢å…³é”®è¯ - æ›´ç»†ç²’åº¦åœ°åˆ†è¯
        keywords = re.split(r'\s+|,|ï¼Œ|ã€|ã€‚|ï¼|ï¼Ÿ|ï¼›|:|ï¼š', query.lower())
        # è¿‡æ»¤å¤ªçŸ­çš„å…³é”®è¯ï¼Œä½†ä¿ç•™æ•°å­—
        keywords = [k for k in keywords if len(k) > 1 or k.isdigit()]  
        
        if not keywords:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå…³é”®è¯ï¼Œä½¿ç”¨æ•´ä¸ªæŸ¥è¯¢ä½œä¸ºä¸€ä¸ªå…³é”®è¯
            keywords = [query.lower()]

        # æœç´¢æ™¯ç‚¹
        if search_type in ["spots", "all"] and not self.spots_df.empty:
            for idx, row in self.spots_df.iterrows():
                score = 0
                matched_keywords = set()  # è®°å½•å·²åŒ¹é…çš„å…³é”®è¯ï¼Œé¿å…é‡å¤è®¡åˆ†
                
                # è®¡ç®—åŒ¹é…åˆ†æ•°
                for col in ['æ™¯ç‚¹åç§°', 'åœ°å€', 'ç®€ä»‹', 'ç‰¹è‰²çœ‹ç‚¹']:
                    if pd.notna(row[col]):
                        text = str(row[col]).lower()
                        for keyword in keywords:
                            # å¦‚æœå…³é”®è¯å·²åŒ¹é…è¿‡ï¼Œè·³è¿‡
                            if keyword in matched_keywords:
                                continue
                                
                            # å®Œå…¨åŒ¹é…ç»™æ›´é«˜åˆ†
                            if keyword == text or f" {keyword} " in f" {text} ":
                                score += 10 if col == 'æ™¯ç‚¹åç§°' else 5
                                matched_keywords.add(keyword)
                            # éƒ¨åˆ†åŒ¹é…
                            elif keyword in text:
                                score += 3 if col == 'æ™¯ç‚¹åç§°' else 1
                                matched_keywords.add(keyword)

                if score > 0:
                    results["spots"].append({
                        "data": row.to_dict(),
                        "score": score,
                        "index": idx
                    })

            # æŒ‰åŒ¹é…åˆ†æ•°æ’åºå¹¶é™åˆ¶ç»“æœæ•°é‡
            results["spots"] = sorted(results["spots"], key=lambda x: x["score"], reverse=True)[:limit]

        # æœç´¢å•†å®¶
        if search_type in ["merchants", "all"] and not self.merchants_df.empty:
            for idx, row in self.merchants_df.iterrows():
                score = 0
                matched_keywords = set()  # è®°å½•å·²åŒ¹é…çš„å…³é”®è¯ï¼Œé¿å…é‡å¤è®¡åˆ†
                
                # è®¡ç®—åŒ¹é…åˆ†æ•°
                for col in ['å•†å®¶', 'ä½ç½®', 'æˆ¿é—´å‹å·', 'ä»·æ ¼']:
                    if pd.notna(row[col]):
                        text = str(row[col]).lower()
                        for keyword in keywords:
                            # å¦‚æœå…³é”®è¯å·²åŒ¹é…è¿‡ï¼Œè·³è¿‡
                            if keyword in matched_keywords:
                                continue
                                
                            # å®Œå…¨åŒ¹é…ç»™æ›´é«˜åˆ†
                            if keyword == text or f" {keyword} " in f" {text} ":
                                score += 10 if col == 'å•†å®¶' else 5
                                matched_keywords.add(keyword)
                            # éƒ¨åˆ†åŒ¹é…
                            elif keyword in text:
                                score += 3 if col == 'å•†å®¶' else 1
                                matched_keywords.add(keyword)

                if score > 0:
                    results["merchants"].append({
                        "data": row.to_dict(),
                        "score": score,
                        "index": idx
                    })

            # æŒ‰åŒ¹é…åˆ†æ•°æ’åºå¹¶é™åˆ¶ç»“æœæ•°é‡
            results["merchants"] = sorted(results["merchants"], key=lambda x: x["score"], reverse=True)[:limit]

        return results

    def vector_search(self, query: str, search_type: str = "all", limit: int = 3) -> Dict[str, List[Dict]]:
        """
        åŸºäºå‘é‡çš„è¯­ä¹‰æœç´¢ï¼Œä½¿ç”¨FAISS

        Args:
            query: æœç´¢æŸ¥è¯¢
            search_type: æœç´¢ç±»å‹('spots', 'merchants', 'all')
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        if self.model is None:
            return {"spots": [], "merchants": []}

        results = {"spots": [], "merchants": []}

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.model.encode([query])
        # ç¡®ä¿å‘é‡æ˜¯float32ç±»å‹å¹¶è¿›è¡ŒL2å½’ä¸€åŒ–
        query_embedding = query_embedding.astype(np.float32)
        faiss.normalize_L2(query_embedding)

        # æœç´¢æ™¯ç‚¹
        if search_type in ["spots", "all"] and self.spots_index is not None and not self.spots_df.empty:
            # ä½¿ç”¨FAISSæ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            # distancesæ˜¯ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œindicesæ˜¯å‘é‡çš„ç´¢å¼•ä½ç½®
            distances, indices = self.spots_index.search(query_embedding, limit)
            
            # è½¬æ¢ç»“æœ
            for i, idx in enumerate(indices[0]):
                if idx < len(self.spots_df) and idx >= 0:  # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                    results["spots"].append({
                        "data": self.spots_df.iloc[idx].to_dict(),
                        "score": float(distances[0][i]),
                        "index": int(idx)
                    })

        # æœç´¢å•†å®¶
        if search_type in ["merchants", "all"] and self.merchants_index is not None and not self.merchants_df.empty:
            # ä½¿ç”¨FAISSæ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            distances, indices = self.merchants_index.search(query_embedding, limit)
            
            # è½¬æ¢ç»“æœ
            for i, idx in enumerate(indices[0]):
                if idx < len(self.merchants_df) and idx >= 0:  # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                    results["merchants"].append({
                        "data": self.merchants_df.iloc[idx].to_dict(),
                        "score": float(distances[0][i]),
                        "index": int(idx)
                    })

        return results

    def search(self, query: str, search_type: str = "all", limit: int = 3) -> Dict[str, Any]:
        """
        ç»¼åˆæœç´¢æ¥å£ï¼šç»“åˆå…³é”®è¯æœç´¢å’Œå‘é‡æœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢
            search_type: æœç´¢ç±»å‹('spots', 'merchants', 'all')
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœ
        """
        # æ‰§è¡Œå…³é”®è¯æœç´¢
        keyword_results = self.keyword_search(query, search_type, limit)

        # æ‰§è¡Œå‘é‡æœç´¢
        vector_results = self.vector_search(query, search_type, limit)

        # åˆå¹¶ç»“æœï¼ˆå»é‡ï¼‰
        combined_results = {"spots": [], "merchants": []}

        # åˆå¹¶æ™¯ç‚¹ç»“æœ
        seen_spots = set()
        for result_list in [keyword_results["spots"], vector_results["spots"]]:
            for item in result_list:
                spot_name = item["data"]["æ™¯ç‚¹åç§°"]
                if spot_name not in seen_spots:
                    seen_spots.add(spot_name)
                    combined_results["spots"].append(item)

        # åˆå¹¶å•†å®¶ç»“æœ
        seen_merchants = set()
        for result_list in [keyword_results["merchants"], vector_results["merchants"]]:
            for item in result_list:
                merchant_name = item["data"]["å•†å®¶"]
                if merchant_name not in seen_merchants:
                    seen_merchants.add(merchant_name)
                    combined_results["merchants"].append(item)

        # é™åˆ¶ç»“æœæ•°é‡
        combined_results["spots"] = combined_results["spots"][:limit]
        combined_results["merchants"] = combined_results["merchants"][:limit]

        return combined_results

    def format_llm_card(self, query: str, content: Any, card_type: str = "llm", llm_content: str = None) -> str:
        """
        ç»Ÿä¸€çš„å¡ç‰‡æ ¼å¼åŒ–å‡½æ•° - å¤„ç†æ‰€æœ‰ç±»å‹çš„æ•°æ®
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            content: å†…å®¹æ•°æ® (å¯ä»¥æ˜¯LLMæ–‡æœ¬ã€æ™¯ç‚¹æ•°æ®å­—å…¸æˆ–å•†å®¶æ•°æ®å­—å…¸)
            card_type: å¡ç‰‡ç±»å‹ ("llm", "spot", "merchant")
            llm_content: LLMç”Ÿæˆçš„å›å¤å†…å®¹ï¼ˆç”¨äºåœ¨æ™¯ç‚¹æˆ–å•†å®¶å¡ç‰‡ä¸­å±•ç¤ºï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„å¡ç‰‡ä¿¡æ¯
        """
        # è·å–å½“å‰æ—¥æœŸä½œä¸ºå»ºè®®å‚è€ƒæ—¶é—´ç‚¹
        current_date = datetime.datetime.now().strftime("%Yå¹´%mæœˆ")
        
        # æ ¹æ®å¡ç‰‡ç±»å‹å¤„ç†ä¸åŒçš„å†…å®¹
        if card_type == "spot":
            # å¤„ç†æ™¯ç‚¹æ•°æ®
            spot_data = content
            # æå–ä¸»è¦ä¿¡æ¯å¹¶ç¡®ä¿å€¼ä¸ºå­—ç¬¦ä¸²
            name = str(spot_data.get("æ™¯ç‚¹åç§°", "æœªçŸ¥æ™¯ç‚¹"))
            address = str(spot_data.get("åœ°å€", "åœ°å€æœªæä¾›"))
            fee = str(spot_data.get("è´¹ç”¨", "è´¹ç”¨ä¿¡æ¯æœªæä¾›"))
            open_time = str(spot_data.get("å¼€æ”¾æ—¶é—´", "å¼€æ”¾æ—¶é—´æœªæä¾›"))
            duration = str(spot_data.get("ç”¨æ—¶å‚è€ƒ", "å‚è€ƒç”¨æ—¶æœªæä¾›"))
            intro = str(spot_data.get("ç®€ä»‹", "æš‚æ— ç®€ä»‹"))
            highlights = str(spot_data.get("ç‰¹è‰²çœ‹ç‚¹", "æš‚æ— ç‰¹è‰²çœ‹ç‚¹"))
            contact = str(spot_data.get("è”ç³»æ–¹å¼", "è”ç³»æ–¹å¼æœªæä¾›"))
            
            # å¤„ç†nanå€¼
            if name == "nan": name = "æœªçŸ¥æ™¯ç‚¹"
            if address == "nan": address = "åœ°å€æœªæä¾›"
            if fee == "nan": fee = "è´¹ç”¨ä¿¡æ¯æœªæä¾›"
            if open_time == "nan": open_time = "å¼€æ”¾æ—¶é—´æœªæä¾›"
            if duration == "nan": duration = "å‚è€ƒç”¨æ—¶æœªæä¾›"
            if intro == "nan": intro = "æš‚æ— ç®€ä»‹"
            if highlights == "nan": highlights = "æš‚æ— ç‰¹è‰²çœ‹ç‚¹"
            if contact == "nan": contact = "è”ç³»æ–¹å¼æœªæä¾›"

            # ç®€åŒ–å†…å®¹ - æˆªæ–­è¿‡é•¿æ–‡æœ¬
            if len(intro) > 100:
                intro = intro[:97] + "..."
            if len(highlights) > 80:
                highlights = highlights[:77] + "..."

            # æ„å»ºå¡ç‰‡ä¿¡æ¯ - æ”¹è¿›å¯è§†åŒ–å¸ƒå±€
            card_content = f"""ã€æ™¯ç‚¹ä¿¡æ¯ã€‘{name}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ åœ°å€ï¼š{address}
ğŸ« é—¨ç¥¨ï¼š{fee}
â° å¼€æ”¾æ—¶é—´ï¼š{open_time}
âŒ› å‚è€ƒæ¸¸è§ˆæ—¶é—´ï¼š{duration}
ğŸ“ è”ç³»ç”µè¯ï¼š{contact}

ğŸ“ æ™¯ç‚¹ç®€ä»‹ï¼š
{intro}

âœ¨ ç‰¹è‰²çœ‹ç‚¹ï¼š
{highlights}"""

            # æ·»åŠ LLMçš„è§‚ç‚¹å’Œå»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
            if llm_content:
                card_content += f"""

ğŸ¤– AIæ—…ä¼´ç‚¹è¯„ï¼š
{llm_content}"""

        elif card_type == "merchant":
            # å¤„ç†å•†å®¶æ•°æ®
            merchant_data = content
            # æå–ä¸»è¦ä¿¡æ¯å¹¶ç¡®ä¿å€¼ä¸ºå­—ç¬¦ä¸²
            name = str(merchant_data.get("å•†å®¶", "æœªçŸ¥å•†å®¶"))
            location = str(merchant_data.get("ä½ç½®", "ä½ç½®æœªæä¾›"))
            room_type = str(merchant_data.get("æˆ¿é—´å‹å·", "æˆ¿å‹æœªæä¾›"))
            price = str(merchant_data.get("ä»·æ ¼", "ä»·æ ¼æœªæä¾›"))
            ground_rooms = str(merchant_data.get("ä¸€æ¥¼æˆ¿é—´æ•°é‡", "æœªçŸ¥"))
            contact = str(merchant_data.get("è”ç³»æ–¹å¼", "è”ç³»æ–¹å¼æœªæä¾›"))
            
            # å¤„ç†nanå€¼
            if name == "nan": name = "æœªçŸ¥å•†å®¶"
            if location == "nan": location = "ä½ç½®æœªæä¾›"
            if room_type == "nan": room_type = "æˆ¿å‹æœªæä¾›"
            if price == "nan": price = "ä»·æ ¼æœªæä¾›"
            if ground_rooms == "nan": ground_rooms = "æœªçŸ¥"
            if contact == "nan": contact = "è”ç³»æ–¹å¼æœªæä¾›"

            # æ„å»ºå¡ç‰‡ä¿¡æ¯ - æ”¹è¿›å¯è§†åŒ–å¸ƒå±€
            card_content = f"""ã€ä½å®¿ä¿¡æ¯ã€‘{name}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ åœ°å€ï¼š{location}
ğŸ  æˆ¿å‹ï¼š{room_type}
ğŸ’° ä»·æ ¼ï¼š{price}
ğŸ§“ ä¸€æ¥¼æˆ¿é—´æ•°é‡ï¼š{ground_rooms} (é€‚åˆè¡ŒåŠ¨ä¸ä¾¿äººå£«)
ğŸ“ è”ç³»ç”µè¯ï¼š{contact}"""

            # æ·»åŠ LLMçš„è§‚ç‚¹å’Œå»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
            if llm_content:
                card_content += f"""

ğŸ¤– AIæ—…ä¼´ç‚¹è¯„ï¼š
{llm_content}"""

        else:
            # å¤„ç†LLMç”Ÿæˆå†…å®¹
            llm_content = content
            
            # æ ¹æ®æŸ¥è¯¢å†…å®¹æ™ºèƒ½é€‰æ‹©å¡ç‰‡æ ‡é¢˜
            title = "ã€AIæ—…ä¼´ç‚¹è¯„ã€‘"
            
            # åŸºäºæŸ¥è¯¢ç±»å‹é€‰æ‹©æ›´å…·ä½“çš„æ ‡é¢˜
            if any(keyword in query for keyword in ["æ™¯ç‚¹", "æ¸¸ç©", "å‚è§‚", "æ™¯åŒº", "ç©", "å»", "æ¸¸è§ˆ"]):
                title = "ã€æ™¯ç‚¹æ¨èã€‘"
            elif any(keyword in query for keyword in ["ä½å®¿", "é…’åº—", "æ°‘å®¿", "å®¢æ ˆ", "ä½", "æˆ¿é—´"]):
                title = "ã€ä½å®¿å»ºè®®ã€‘"
            elif any(keyword in query for keyword in ["ç¾é£Ÿ", "åƒ", "é¤å…", "å°åƒ", "èœ"]):
                title = "ã€ç¾é£ŸæŒ‡å—ã€‘"
            elif any(keyword in query for keyword in ["äº¤é€š", "æ€ä¹ˆå»", "è·¯çº¿", "åˆ°è¾¾", "è½¦"]):
                title = "ã€äº¤é€šæŒ‡å—ã€‘"
            elif any(keyword in query for keyword in ["å»ºè®®", "æ”»ç•¥", "è¡Œç¨‹", "è·¯çº¿", "è§„åˆ’"]):
                title = "ã€è¡Œç¨‹å»ºè®®ã€‘"
                
            # æ„å»ºå¡ç‰‡ä¿¡æ¯ - ä½¿ç”¨æ›´ç²¾ç¾çš„æ ¼å¼
            card_content = f"""{title}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{llm_content}"""
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ é€‚è€æç¤ºï¼ˆé€‚ç”¨äºæ‰€æœ‰å¡ç‰‡ç±»å‹ï¼‰
        accessibility_note = ""
        if any(keyword in query.lower() for keyword in ["è€äºº", "å¹´é¾„å¤§", "çˆ¶æ¯", "çˆ·çˆ·", "å¥¶å¥¶", "è€å¹´", "é•¿è¾ˆ"]):
            # æ·»åŠ é€‚è€åŒ–æç¤º
            accessibility_note = """
ğŸ‘´ğŸ‘µ é€‚è€è´´å£«ï¼š
â€¢ è¯·é€‰æ‹©ç¼“å¡é€šé“å’Œç”µæ¢¯è®¾æ–½
â€¢ å»ºè®®é”™å³°å‡ºè¡Œï¼Œé¿å¼€äººæµé«˜å³°
â€¢ éšèº«æºå¸¦å¸¸ç”¨è¯å“å’Œè€äººè¯ä»¶
â€¢ å®‰æ’å……è¶³ä¼‘æ¯æ—¶é—´ï¼Œé¿å…è¿‡åº¦ç–²åŠ³
"""
        
        # æ£€æŸ¥æ˜¯å¦æ¶‰åŠè¡ŒåŠ¨ä¸ä¾¿
        if any(keyword in query.lower() for keyword in ["è½®æ¤…", "è¡ŒåŠ¨ä¸ä¾¿", "è…¿è„š", "ä¸æ–¹ä¾¿", "æ®‹ç–¾", "æ— éšœç¢"]):
            # æ·»åŠ æ— éšœç¢æç¤º
            accessibility_note = """
â™¿ æ— éšœç¢è´´å£«ï¼š
â€¢ å‡ºå‘å‰è¯·ç”µè¯ç¡®è®¤æ™¯ç‚¹/é…’åº—æ— éšœç¢è®¾æ–½æƒ…å†µ
â€¢ é€‰æ‹©é…æœ‰è½®æ¤…é€šé“å’Œæ— éšœç¢å«ç”Ÿé—´çš„åœºæ‰€
â€¢ å»ºè®®æå‰é¢„çº¦æ— éšœç¢æœåŠ¡æˆ–è®¾æ–½
â€¢ è€ƒè™‘é€‰æ‹©ä¸€æ¥¼æˆ¿é—´æˆ–æœ‰ç”µæ¢¯çš„ä½å®¿
"""
        
        # æ·»åŠ é¡µè„šä¿¡æ¯
        footer = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ•’ {current_date}æ›´æ–°
ğŸ“ ä»¥ä¸Šä¿¡æ¯ç”±å¤§ç†æ—…ä¼´AIæä¾›ï¼Œä»…ä¾›å‚è€ƒ
ğŸ“ éœ€äº†è§£æ›´å¤šè¯¦æƒ…ï¼Œè¯·è”ç³»å½“åœ°æ—…æ¸¸æœåŠ¡
"""
        
        # ç»„åˆæœ€ç»ˆå¡ç‰‡
        return card_content + accessibility_note + footer
    
    # æä¾›å‘åå…¼å®¹çš„å‡½æ•°
    def format_spot_card(self, spot_data: Dict[str, Any]) -> str:
        """å‘åå…¼å®¹çš„æ™¯ç‚¹å¡ç‰‡æ ¼å¼åŒ–å‡½æ•°"""
        return self.format_llm_card("æ™¯ç‚¹", spot_data, card_type="spot")
        
    def format_merchant_card(self, merchant_data: Dict[str, Any]) -> str:
        """å‘åå…¼å®¹çš„å•†å®¶å¡ç‰‡æ ¼å¼åŒ–å‡½æ•°"""
        return self.format_llm_card("ä½å®¿", merchant_data, card_type="merchant")

    def find_nearby_merchants(self, spot_address: str) -> List[Dict[str, Any]]:
        """
        æ ¹æ®æ™¯ç‚¹åœ°å€æŸ¥æ‰¾é™„è¿‘çš„å•†å®¶

        Args:
            spot_address: æ™¯ç‚¹åœ°å€

        Returns:
            é™„è¿‘å•†å®¶åˆ—è¡¨
        """
        if self.merchants_df.empty:
            return []
            
        # å¤„ç†spot_addressä¸ºnançš„æƒ…å†µ
        if pd.isna(spot_address) or str(spot_address).lower() == "nan":
            spot_address = ""

        nearby_merchants = []
        # æå–åœ°å€ä¸­çš„åŒºåŸŸä¿¡æ¯
        address_parts = re.split(r'[å¸‚åŒºå¿ä¹¡é•‡æ‘]', str(spot_address))

        for _, merchant in self.merchants_df.iterrows():
            # è·å–å•†å®¶ä½ç½®å¹¶ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            location = str(merchant.get("ä½ç½®", ""))
            if location.lower() == "nan":
                location = ""
                
            match = False

            # æ£€æŸ¥åœ°å€æ˜¯å¦åŒ…å«ç›¸åŒçš„åŒºåŸŸå…³é”®è¯
            for part in address_parts:
                if part and len(part) > 1 and part in location:
                    match = True
                    break

            if match:
                nearby_merchants.append(merchant.to_dict())

        return nearby_merchants[:3]  # é™åˆ¶è¿”å›ç»“æœæ•°é‡

    def format_as_card(self, query: str, llm_content: str) -> str:
        """
        å°†LLMç”Ÿæˆçš„å›å¤è½¬æ¢ä¸ºå¡ç‰‡æ ¼å¼ (å…¼å®¹æ—§æ¥å£)
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            llm_content: LLMç”Ÿæˆçš„å†…å®¹
            
        Returns:
            æ ¼å¼åŒ–çš„å¡ç‰‡æˆ–çº¯æ–‡æœ¬
        """
        # å°è¯•è§£æJSONï¼ˆé€‚é…æ–°æ ¼å¼ï¼‰
        try:
            if isinstance(llm_content, str) and (llm_content.startswith('{') or llm_content.strip().startswith('{')):
                llm_json = json.loads(llm_content)
                needs_card = llm_json.get("needs_card", "no").lower() == "yes"
                content = llm_json.get("content", "")
                
                if not needs_card:
                    # ç›´æ¥è¿”å›å†…å®¹ï¼Œä¸ä½¿ç”¨å¡ç‰‡æ ¼å¼
                    return content
                else:
                    # ä½¿ç”¨å¡ç‰‡æ ¼å¼
                    return self.format_llm_card(query, content, card_type="llm")
        except (json.JSONDecodeError, AttributeError):
            pass  # ä¸æ˜¯JSONæ ¼å¼ï¼Œç»§ç»­ä½¿ç”¨æ—§çš„å¤„ç†æ–¹å¼
        
        # é»˜è®¤ä½¿ç”¨é€šç”¨å¡ç‰‡æ ¼å¼
        return self.format_llm_card(query, llm_content, card_type="llm")

    def process_query(self, query: str, user_profile: Optional[Dict] = None, llm_content: Optional[str] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œè¿”å›ç»“æ„åŒ–ä¿¡æ¯

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            user_profile: ç”¨æˆ·ç”»åƒä¿¡æ¯
            llm_content: LLMç”Ÿæˆçš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰

        Returns:
            å¤„ç†ç»“æœ
        """
        # åˆ†ææŸ¥è¯¢æ„å›¾
        if any(keyword in query for keyword in ["ä½å®¿", "é…’åº—", "æ°‘å®¿", "å®¢æ ˆ", "ä½", "æˆ¿é—´"]):
            search_type = "merchants"
        elif any(keyword in query for keyword in ["æ™¯ç‚¹", "æ¸¸ç©", "å‚è§‚", "æ™¯åŒº", "ç©", "å»"]):
            search_type = "spots"
        else:
            search_type = "all"

        # æ‰§è¡Œæœç´¢
        results = self.search(query, search_type=search_type, limit=2)
        
        # æå–æ™¯ç‚¹å’Œå•†å®¶æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        spot_data = None
        merchant_data = None
        
        if results["spots"]:
            spot_data = results["spots"][0]["data"]
            
        if results["merchants"]:
            merchant_data = results["merchants"][0]["data"]

        # é»˜è®¤å›å¤ç±»å‹ä¸ºå¡ç‰‡æ ¼å¼çš„LLMå†…å®¹
        default_content = "éå¸¸æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ä¸æ‚¨æŸ¥è¯¢ç›¸å…³çš„å…·ä½“ä¿¡æ¯ã€‚è¯·å°è¯•è¯¢é—®å¤§ç†çš„çƒ­é—¨æ™¯ç‚¹ã€å¤åŸå‘¨è¾¹ä½å®¿ç­‰æ›´å…·ä½“çš„é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚"
        
        # ä½¿ç”¨ä¼ å…¥çš„LLMå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        llm_text = llm_content if llm_content else default_content
        
        # å¤„ç†LLMçš„JSONå“åº”
        try:
            # åªæœ‰å½“LLMå†…å®¹æ˜¯å­—ç¬¦ä¸²ä¸”å¯èƒ½æ˜¯JSONæ—¶æ‰å°è¯•è§£æ
            if llm_text and isinstance(llm_text, str) and ('{' in llm_text and '}' in llm_text):
                # æ¸…ç†å¯èƒ½åŒ…å«çš„ä»£ç å—æ ‡è®°
                json_str = llm_text.strip()
                if "```json" in json_str:
                    # æå–JSONéƒ¨åˆ†
                    start = json_str.find("```json") + 7
                    end = json_str.rfind("```")
                    if end > start:
                        json_str = json_str[start:end].strip()
                
                # è§£æJSON
                llm_json = json.loads(json_str)
                needs_card = llm_json.get("needs_card", "no").lower() == "yes"
                content = llm_json.get("content", "")
                
                # é¦–å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦å¡ç‰‡
                if needs_card:
                    # å¦‚æœéœ€è¦å¡ç‰‡ï¼Œå¹¶ä¸”æœ‰ç›¸å…³æ•°æ®ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨æ•°æ®ä¿¡æ¯å¹¶æ•´åˆLLMå†…å®¹
                    if search_type == "spots" and spot_data:
                        response = {
                            "type": "spot", 
                            "content": self.format_llm_card(query, spot_data, card_type="spot", llm_content=content)
                        }
                    elif search_type == "merchants" and merchant_data:
                        response = {
                            "type": "merchant", 
                            "content": self.format_llm_card(query, merchant_data, card_type="merchant", llm_content=content)
                        }
                    else:
                        # æ²¡æœ‰ç‰¹å®šæ•°æ®ï¼Œä½¿ç”¨LLMå¡ç‰‡
                        response = {
                            "type": "llm_card", 
                            "content": self.format_llm_card(query, content, card_type="llm")
                        }
                else:
                    # å¦‚æœä¸éœ€è¦å¡ç‰‡ï¼Œç›´æ¥è¿”å›LLMå†…å®¹
                    response = {
                        "type": "text", 
                        "content": content
                    }
            else:
                # å½“è¾“å…¥ä¸æ˜¯JSONæ ¼å¼æ—¶ï¼Œå°è¯•å¯»æ‰¾æ—§æ ¼å¼çš„æ ‡è®°
                if isinstance(llm_text, str) and llm_text.startswith("[CARD]"):
                    # æ—§æ ¼å¼å¡ç‰‡æ ‡è®°
                    content = llm_text.replace("[CARD]", "").strip()
                    response = {
                        "type": "llm_card", 
                        "content": self.format_llm_card(query, content, card_type="llm")
                    }
                elif isinstance(llm_text, str) and llm_text.startswith("[TEXT]"):
                    # æ—§æ ¼å¼æ–‡æœ¬æ ‡è®°
                    content = llm_text.replace("[TEXT]", "").strip()
                    response = {
                        "type": "text", 
                        "content": content
                    }
                else:
                    # é»˜è®¤ä½¿ç”¨LLMå›å¤å†…å®¹
                    response = {
                        "type": "text", 
                        "content": llm_text
                    }
        except (json.JSONDecodeError, AttributeError) as e:
            # ä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†é”™è¯¯
            print(f"JSONè§£ææç¤º (ä¸å½±å“ä½¿ç”¨): {str(e)}")
            
            # å°è¯•ä½¿ç”¨å†…å®¹çš„åŸºæœ¬æ ¼å¼
            if isinstance(llm_text, str) and ("[CARD]" in llm_text or "needs_card" in llm_text.lower()):
                # çœ‹èµ·æ¥åƒæ˜¯æœ‰å¡ç‰‡æ ‡è®°ï¼Œä½¿ç”¨å¡ç‰‡æ ¼å¼
                if "[CARD]" in llm_text:
                    content = llm_text.replace("[CARD]", "").strip()
                else:
                    content = llm_text
                    
                response = {
                    "type": "llm_card", 
                    "content": self.format_llm_card(query, content, card_type="llm")
                }
            else:
                # é»˜è®¤ä½¿ç”¨æ–‡æœ¬æ ¼å¼
                response = {
                    "type": "text", 
                    "content": llm_text if isinstance(llm_text, str) else default_content
                }

        return response

    def retrieve(self, query: str, top_k: int = 3) -> str:
        """
        æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ï¼Œå¹¶æ ¼å¼åŒ–ä¸ºæ–‡æœ¬ä»¥ä¼ é€’ç»™LLM
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›çš„ç»“æœæ•°é‡
            
        Returns:
            æ£€ç´¢åˆ°çš„ä¿¡æ¯æ–‡æœ¬
        """
        # ç¡®å®šæœç´¢ç±»å‹
        if any(keyword in query for keyword in ["ä½å®¿", "é…’åº—", "æ°‘å®¿", "å®¢æ ˆ", "ä½", "æˆ¿é—´"]):
            search_type = "merchants"
        elif any(keyword in query for keyword in ["æ™¯ç‚¹", "æ¸¸ç©", "å‚è§‚", "æ™¯åŒº", "ç©", "å»", "æ¸¸è§ˆ"]):
            search_type = "spots"
        else:
            search_type = "all"
            
        # æ‰§è¡Œæœç´¢
        results = self.search(query, search_type=search_type, limit=top_k)
        
        # æ ¼å¼åŒ–ç»“æœä¸ºæ–‡æœ¬
        retrieved_info = []
        
        # å¤„ç†æ™¯ç‚¹ä¿¡æ¯
        if results["spots"]:
            retrieved_info.append("ç›¸å…³æ™¯ç‚¹ä¿¡æ¯ï¼š")
            for i, item in enumerate(results["spots"], 1):
                spot = item["data"]
                name = str(spot.get("æ™¯ç‚¹åç§°", "æœªçŸ¥æ™¯ç‚¹"))
                if name == "nan": name = "æœªçŸ¥æ™¯ç‚¹"
                
                address = str(spot.get("åœ°å€", "åœ°å€æœªæä¾›"))
                if address == "nan": address = "åœ°å€æœªæä¾›"
                
                fee = str(spot.get("è´¹ç”¨", "è´¹ç”¨ä¿¡æ¯æœªæä¾›"))
                if fee == "nan": fee = "è´¹ç”¨ä¿¡æ¯æœªæä¾›"
                
                intro = str(spot.get("ç®€ä»‹", "æš‚æ— ç®€ä»‹"))
                if intro == "nan": intro = "æš‚æ— ç®€ä»‹"
                if len(intro) > 100:
                    intro = intro[:97] + "..."
                
                retrieved_info.append(f"{i}. {name}ï¼šä½äº{address}ï¼Œé—¨ç¥¨{fee}ã€‚{intro}")
                
        # å¤„ç†å•†å®¶ä¿¡æ¯
        if results["merchants"]:
            retrieved_info.append("\nç›¸å…³ä½å®¿ä¿¡æ¯ï¼š")
            for i, item in enumerate(results["merchants"], 1):
                merchant = item["data"]
                name = str(merchant.get("å•†å®¶", "æœªçŸ¥å•†å®¶"))
                if name == "nan": name = "æœªçŸ¥å•†å®¶"
                
                location = str(merchant.get("ä½ç½®", "ä½ç½®æœªæä¾›"))
                if location == "nan": location = "ä½ç½®æœªæä¾›"
                
                room_type = str(merchant.get("æˆ¿é—´å‹å·", "æˆ¿å‹æœªæä¾›"))
                if room_type == "nan": room_type = "æˆ¿å‹æœªæä¾›"
                
                price = str(merchant.get("ä»·æ ¼", "ä»·æ ¼æœªæä¾›"))
                if price == "nan": price = "ä»·æ ¼æœªæä¾›"
                
                retrieved_info.append(f"{i}. {name}ï¼šä½äº{location}ï¼Œæä¾›{room_type}ï¼Œä»·æ ¼{price}")
                
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœ
        if not retrieved_info:
            return "æˆ‘æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨æŸ¥è¯¢ç›¸å…³çš„å…·ä½“æ™¯ç‚¹æˆ–ä½å®¿ä¿¡æ¯ï¼Œä½†æˆ‘ä¼šå°½åŠ›å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
            
        return "\n".join(retrieved_info)


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    retrieval = DataRetrievalModule()

    # æµ‹è¯•æŸ¥è¯¢æ™¯ç‚¹
    query1 = "æœ‰ä»€ä¹ˆé€‚åˆè€äººçš„æ™¯ç‚¹æ¨è"
    result1 = retrieval.process_query(query1, {"age": "65", "mobility_status": "è¡Œèµ°ç¼“æ…¢"})
    print(f"æŸ¥è¯¢: {query1}")
    print(result1["content"])
    print("-" * 50)

    # æµ‹è¯•æŸ¥è¯¢ä½å®¿
    query2 = "å¤§ç†å¤åŸé™„è¿‘æœ‰ä»€ä¹ˆä¾¿å®œçš„ä½å®¿"
    result2 = retrieval.process_query(query2)
    print(f"æŸ¥è¯¢: {query2}")
    print(result2["content"])
